{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.api.types import CategoricalDtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_baseline_model():\n",
    "    def __init__(self, filename, sensor):\n",
    "        self.sensor = sensor\n",
    "        self.data = pd.read_csv(filename,\n",
    "                        usecols=[0,sensor + 1],\n",
    "                        index_col=[0],\n",
    "                        parse_dates=[0])\n",
    "        \n",
    "        label = str(sensor)\n",
    "        cat_type = CategoricalDtype(categories=['Monday','Tuesday',\n",
    "                                            'Wednesday',\n",
    "                                            'Thursday','Friday',\n",
    "                                            'Saturday','Sunday'],\n",
    "                                ordered=True)\n",
    "\n",
    "        df = self.data.copy()\n",
    "\n",
    "        # here there are a few more features that are not utilized by this model for simplicity\n",
    "        # but can be added later \n",
    "        df['date'] = df.index\n",
    "        df['hour'] = df['date'].dt.hour\n",
    "        df['dayofweek'] = df['date'].dt.dayofweek\n",
    "        df['weekday'] = df['date'].dt.day_name()\n",
    "        df['weekday'] = df['weekday'].astype(cat_type)\n",
    "        df['quarter'] = df['date'].dt.quarter\n",
    "        df['month'] = df['date'].dt.month\n",
    "        df['year'] = df['date'].dt.year\n",
    "        df['dayofyear'] = df['date'].dt.dayofyear\n",
    "        df['dayofmonth'] = df['date'].dt.day\n",
    "        df['date_offset'] = (df.date.dt.month*100 + df.date.dt.day - 320)%1300\n",
    "\n",
    "        df['season'] = pd.cut(df['date_offset'], [0, 300, 602, 900, 1300], \n",
    "                            labels=['Spring', 'Summer', 'Fall', 'Winter']\n",
    "                    )\n",
    "\n",
    "        # Other features are not that useful \n",
    "        X = df[['hour', 'weekday','season']]\n",
    "        y = df[label]\n",
    "\n",
    "        self.features_and_target =  pd.concat([X, y], axis=1)\n",
    "        self.group = self.features_and_target.groupby(['hour', 'weekday', 'season'])[str(sensor)].mean()\n",
    "        self.pivot_group = self.features_and_target.groupby(['hour', 'weekday', 'season'])[str(sensor)].mean().reset_index()\n",
    "\n",
    "    \n",
    "    # Time is pd.DatetimeIndex()\n",
    "    # example: time  = pd.DatetimeIndex([\"8/1/2016 10:00:00\"])\n",
    "    # returns a numpy.float64 which is the prediction for the date provided\n",
    "    def predict_one(self, time):\n",
    "        date_offset = (time.month*100 + time.day- 320)%1300\n",
    "\n",
    "        season = pd.cut(date_offset, [0, 300, 602, 900, 1300], \n",
    "                            labels=['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "        return self.group[time.hour[0]][time.day_name()[0]][season[0]]\n",
    "    \n",
    "    \n",
    "\n",
    "    # format of the file: date - value\n",
    "    # returns a numpy.ndarray of the predicted values only (numpy.float64)\n",
    "    def predict_many(self, filename):\n",
    "        dates = pd.read_csv(filename, usecols=[0],\n",
    "                        index_col=[0],\n",
    "                        parse_dates=[0])\n",
    "\n",
    "        output = np.zeros(len(dates.index))\n",
    "       \n",
    "        date_offset = (time.month*100 + time.day- 320)%1300\n",
    "        season = pd.cut(date_offset, [0, 300, 602, 900, 1300], \n",
    "                            labels=['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "        i = 0\n",
    "        for date in dates.index:            \n",
    "            output[i] = (self.group[pd.DatetimeIndex([date]).hour[0]][pd.DatetimeIndex([date]).day_name()[0]][season[0]])\n",
    "            i += 1\n",
    "\n",
    "        return output\n",
    "\n",
    "    # doesn't work well right now lmao\n",
    "    # index : array of strings: either one or two of [\"hour\", \"weekday\", \"season\"]\n",
    "    # string one of \"hour\", \"weekday\", \"season\"\n",
    "    def plot(self, index, column):\n",
    "        pivot_table = self.pivot_group.pivot_table(index=index, columns=column, values=str(self.sensor))\n",
    "        pivot_table.plot(kind='bar', figsize=(10, 6))\n",
    "        plt.title(f'Mean Target Value by Hour, Day, and Season')\n",
    "        plt.xlabel(index)\n",
    "        plt.ylabel('Mean Target Value')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title=column, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6644\\3104805867.py:41: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  self.group = self.features_and_target.groupby(['hour', 'weekday', 'season'])[str(sensor)].mean()\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6644\\3104805867.py:42: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  self.pivot_group = self.features_and_target.groupby(['hour', 'weekday', 'season'])[str(sensor)].mean().reset_index()\n"
     ]
    }
   ],
   "source": [
    "sensor = 6\n",
    "model = random_baseline_model('./sample-data/traffic.csv', sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05936923076923077"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time = pd.DatetimeIndex([\"11/13/2016 10:00:00\"])\n",
    "k = model.predict_one(time)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor_6.csv\n"
     ]
    }
   ],
   "source": [
    "# predict the test data\n",
    "filename = \"sensor_\" + str(sensor) + \".csv\"\n",
    "print(filename)\n",
    "predictions = model.predict_many(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6644\\1555280279.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  actual_values_df = pd.read_csv(\"sensor_\" + str(sensor) +\".csv\", usecols=[1],\n"
     ]
    }
   ],
   "source": [
    "# get the actual values from the test data\n",
    "actual_values_df = pd.read_csv(\"sensor_\" + str(sensor) +\".csv\", usecols=[1],\n",
    "                        index_col=[0],\n",
    "                        parse_dates=[0])\n",
    "\n",
    "actual_values = np.zeros(len(actual_values_df.index))\n",
    "for i in range(len(actual_values_df.index)):\n",
    "    actual_values[i] = (actual_values_df.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a file for the test data with the dates only\n",
    "df = pd.read_csv(\"sensor_\"+ str(sensor)+ \"_dates_only.csv\")\n",
    "\n",
    "# add the model's predictions to that file\n",
    "df[sensor] = predictions\n",
    "df.to_csv(\"sensor_\" + str(sensor) +\"_predition.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.8264651917664867\n",
      "mae = 0.01295616445997569\n",
      "mse = 0.0007620875422870853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "epsilon = 0.00000001\n",
    "r2 = r2_score(actual_values, predictions)\n",
    "mae = mean_absolute_error(actual_values, predictions)\n",
    "mse = mean_squared_error(actual_values, predictions)\n",
    "\n",
    "print(f\"r2 = {r2}\")\n",
    "print(f\"mae = {mae}\")\n",
    "print(f\"mse = {mse}\")\n",
    "\n",
    "# for sensor 6:\n",
    "# r2 = 0.8529282859104332\n",
    "# mae = 0.013322875828815445\n",
    "# mse = 0.0006458734260370798"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
